Spark快速大数据分析[美] 卡劳（Holden Karau）
* what is spark
  spark 是一个用来实现快速而通用的集群计算的平台
  - spark core
  - spark sql
  - spark streaming
  - MLlib
  - GraphX
  - 集群管理器
    - 自带简易调度器，独立调度器
    - Hadoop YARN
    - Apache Mesos
  - Spark的存储层次
    - 支持本地文件,HDFS,Hive,HBase
    - 文件格式:文本文件,SequenceFile,Avro,Parquet
  - shell
    spark shell 可用来与分布式存储在许多机器的内存或者硬盘上的数据进行交互
    python shell / scala shell
  - SparkContext
    每个Sparkyingy
* RDD
  RDD(resilient distributed dataset)
* spark use
** spark base
   rdd(resilient distributed dataset)
** spark install
   函数式编程
   shell下执行:paste
** spark shell
   bin/spark-shell
   - 创建RDD
     sc.parallelize()
   - RDD操作
     + 转化操作
       返回的是RDD
       map()
       filter()
     + 行动操作
       返回结果或把结果写入外部系统的操作,返回的是其他数据类型
   
** idea spark scala
   scala 项目手动打包
   删除scala 和spark的包

   执行中 spark-submit --class com.nti.spark.SparkTags spark_scala_jar.jar

   sbt 构建项目 需要等待sbt版本下载好才会生成src目录
   
** idea spark java 
   1. jre 1.5 换成1.8
** rdd & dataframe

